import hashlib
import os
import random
import shutil
import numpy as np
from collections import OrderedDict
import gymnasium as gym
from gymnasium import spaces

from malware_gym.envs.utils import *
from malware_gym.envs.feature_extractor import pefeature
from malware_gym.envs.action import manipulate2 as manipulate

ACTION_LOOKUP_TABLE = {i: act for i, act in enumerate(manipulate.ACTION_TABLE.keys())}


def predict(sample):
    return 0


class MalwareEnv(gym.Env):
    metadata = {"render_modes": ["human"]}

    def __init__(
        self,
        samples_path,
        original_samples_path,
        output_path,
        modified_samples_path,
        maxturns=10,
    ):
        self.action_space = spaces.Discrete(len(ACTION_LOOKUP_TABLE))
        self.maxturns = maxturns
        self.feature_extractor = pefeature.PEFeatureExtractor2()
        self.action_history = OrderedDict()
        self.samples_path = samples_path
        print(os.listdir(samples_path))
        self.sample = None
        self.output_path = output_path
        self.save_modified_samples = modified_samples_path
        self.original_samples_path = original_samples_path

        self.reset()
        pass

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.turns = 0

        while True:
            # get random sample
            self.current_sample_path = random.choice(self.samples_path)
            self.sample = read_file(self.current_sample_path)

            self.history[self.current_sample_path] = {"actions": [], "evaded": False}
            label = predict(self.current_sample_path)
            if label == 0:
                continue

            self.observation_space = self.feature_extractor.extract(self.sample)

            break

        return np.asarray(self.observation_space)

    def step(self, action):
        self.turns += 1
        self._take_action(action)

        try:
            self.label = predict(self.current_sample_path)
        except:
            print("Classification failure")
            episode_over = True
        else:
            self.observation_space = self.feature_extractor.extract(self.sample)
            if self.label == 0:
                reward = 1
                episode_over = True
                self.action_history[self.current_sample_path]["evaded"] = True
                m = hashlib.sha256()
                m.update(self.sample)
                sha256 = m.hexdigest()
                self.action_history[self.current_sample_path]["sha256"] = sha256

                # save modified sample
                with open(os.path.join(self.save_modified_samples, sha256), "wb") as f:
                    f.write(self.sample)

                # copy original sample to original_samples_path
                shutil.copy(self.current_sample_path, self.original_samples_path)

            elif self.turns >= self.maxturns:
                reward = 0
                episode_over = True
            else:
                reward = 0
                episode_over = False
        if episode_over:
            print("Episode over, reward = {}".format(reward))

        return self.observation_space, reward, episode_over, {}

    def _take_action(self, action):
        assert action < len(ACTION_LOOKUP_TABLE)
        action = ACTION_LOOKUP_TABLE[action]
        print(action)
        self.action_history[self.current_sample_path]["actions"].append(action)
        self.sample = bytes(manipulate.modify_without_breaking(self.sample, [action]))
        pass

    def render(self):
        pass
